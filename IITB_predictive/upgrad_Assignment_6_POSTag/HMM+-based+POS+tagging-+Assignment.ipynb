{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS tagging using modified Viterbi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\ankit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing libraries\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "nltk.download('universal_tagset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the Treebank tagged sentences\n",
    "nltk_data = list(nltk.corpus.treebank.tagged_sents(tagset='universal'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Splitting the data into Train and Validation set   #test_set = validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validation = train_test_split(nltk_data, train_size=0.95, test_size=0.05, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pre-processing on Train set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tagged_words = [tup for sent in train for tup in sent]  # gets all WORD + TAGS\n",
    "tags = {tag for word, tag in train_tagged_words}    # create a Set of TAGS   \n",
    "train_vocab = {word for word,tag in train_tagged_words}  # create a SET of Words in TRAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the vanilla Viterbi based POS tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emission and Transition Probability "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute Emission Probability\n",
    "def word_given_tag(word, tag, train_bag=train_tagged_words):\n",
    "    \"\"\"\n",
    "    Emission probability of word(w) and tag(t) is,\n",
    "    Number of times word (w) has been tagged with (t) / numb of times t Appear\n",
    "\n",
    "    :param word: the Word (W)\n",
    "    :param tag: The  Tag (t) for word (W)\n",
    "    :param train_bag: corpus of word and their tags\n",
    "    :return: freq of (w|t), freg of tag (t)\n",
    "    \"\"\"\n",
    "    tag_list = [pair for pair in train_bag if pair[1] == tag]\n",
    "    count_tag = len(tag_list)  # total number of times the passed tag occurred in train_bag\n",
    "    w_given_tag_list = [pair[0] for pair in tag_list if pair[0] == word]\n",
    "    # now calculate the total number of times the passed word occurred as the passed tag.\n",
    "    count_w_given_tag = len(w_given_tag_list)\n",
    "    return count_w_given_tag, count_tag\n",
    "\n",
    "\n",
    "# compute  Transition Probability\n",
    "def t2_given_t1(t2, t1, train_bag=train_tagged_words):\n",
    "    \"\"\"\n",
    "    Prob of trainsition of tag(t1) to tag(t2) = no of times (t2|t1)/ num of (t1) appears\n",
    "    :param t2: tag\n",
    "    :param t1: tag\n",
    "    :param train_bag: Reference corpus\n",
    "    :return: count of (t2|t1), count of t1\n",
    "    \"\"\"\n",
    "    tags = [pair[1] for pair in train_bag]\n",
    "    count_t1 = len([t for t in tags if t==t1])\n",
    "    count_t2_t1 = 0\n",
    "    for index in range(len(tags)-1):\n",
    "        if tags[index]==t1 and tags[index+1] == t2:\n",
    "            count_t2_t1 += 1\n",
    "    return count_t2_t1, count_t1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viterbi Algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viterbi Algorithm\n",
    "def Viterbi(words, train_bag=train_tagged_words):\n",
    "    \"\"\"\n",
    "    words:     Individual Words from Test data set for POS Tagging\n",
    "    train_bag: WORD + TAGS of Train Data -->[('Reliance', 'NOUN'),('confirmed', 'VERB'),('the', 'DET'),('filing', 'NOUN')]\n",
    "    \"\"\"\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))  # gives list of unique Tags\n",
    "    for key, word in enumerate(words):\n",
    "        # initialise list of probability column for a given observation\n",
    "        \n",
    "        p = []\n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]      # getting transition prob from Pandas DF created\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "\n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0] / word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p\n",
    "            p.append(state_probability)\n",
    "\n",
    "        pmax = max(p)\n",
    "        # getting state for which probability is maximum\n",
    "        state_max = T[p.index(pmax)]\n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transition Matrix Creation (T * T)\n",
    "\n",
    "    creating t * t transition matrix of tags, t= no of tags\n",
    "    Matrix(i, j) represents P(jth tag after the ith tag)\n",
    "    \n",
    "    * Converting this Matrix to Dataframe for Better visulaization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_matrix = np.zeros((len(tags), len(tags)), dtype='float32')\n",
    "for i, t1 in enumerate(list(tags)):\n",
    "    for j, t2 in enumerate(list(tags)):\n",
    "        tags_matrix[i, j] = t2_given_t1(t2, t1)[0]/t2_given_t1(t2, t1)[1]\n",
    "        \n",
    "        \n",
    "# convert the matrix to a df for better readability\n",
    "tags_df = pd.DataFrame(tags_matrix, columns = list(tags), index=list(tags))\n",
    "del tags_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DET</th>\n",
       "      <th>CONJ</th>\n",
       "      <th>NUM</th>\n",
       "      <th>.</th>\n",
       "      <th>ADV</th>\n",
       "      <th>VERB</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADP</th>\n",
       "      <th>PRON</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>X</th>\n",
       "      <th>PRT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DET</th>\n",
       "      <td>0.005676</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>0.022220</td>\n",
       "      <td>0.017993</td>\n",
       "      <td>0.012438</td>\n",
       "      <td>0.039850</td>\n",
       "      <td>0.204323</td>\n",
       "      <td>0.009540</td>\n",
       "      <td>0.003744</td>\n",
       "      <td>0.638087</td>\n",
       "      <td>0.045405</td>\n",
       "      <td>0.000242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CONJ</th>\n",
       "      <td>0.121339</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>0.039981</td>\n",
       "      <td>0.034868</td>\n",
       "      <td>0.055323</td>\n",
       "      <td>0.156671</td>\n",
       "      <td>0.118085</td>\n",
       "      <td>0.052534</td>\n",
       "      <td>0.058113</td>\n",
       "      <td>0.349140</td>\n",
       "      <td>0.008833</td>\n",
       "      <td>0.004649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM</th>\n",
       "      <td>0.003276</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>0.184932</td>\n",
       "      <td>0.117332</td>\n",
       "      <td>0.002978</td>\n",
       "      <td>0.018761</td>\n",
       "      <td>0.034247</td>\n",
       "      <td>0.036033</td>\n",
       "      <td>0.001489</td>\n",
       "      <td>0.350208</td>\n",
       "      <td>0.210542</td>\n",
       "      <td>0.026504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0.173335</td>\n",
       "      <td>0.057538</td>\n",
       "      <td>0.081003</td>\n",
       "      <td>0.093320</td>\n",
       "      <td>0.052324</td>\n",
       "      <td>0.089095</td>\n",
       "      <td>0.043963</td>\n",
       "      <td>0.091342</td>\n",
       "      <td>0.066349</td>\n",
       "      <td>0.222242</td>\n",
       "      <td>0.026971</td>\n",
       "      <td>0.002427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADV</th>\n",
       "      <td>0.069891</td>\n",
       "      <td>0.006956</td>\n",
       "      <td>0.030474</td>\n",
       "      <td>0.137131</td>\n",
       "      <td>0.080490</td>\n",
       "      <td>0.343491</td>\n",
       "      <td>0.129182</td>\n",
       "      <td>0.118582</td>\n",
       "      <td>0.014906</td>\n",
       "      <td>0.031467</td>\n",
       "      <td>0.023186</td>\n",
       "      <td>0.014243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           DET      CONJ       NUM         .       ADV      VERB       ADJ  \\\n",
       "DET   0.005676  0.000483  0.022220  0.017993  0.012438  0.039850  0.204323   \n",
       "CONJ  0.121339  0.000465  0.039981  0.034868  0.055323  0.156671  0.118085   \n",
       "NUM   0.003276  0.013699  0.184932  0.117332  0.002978  0.018761  0.034247   \n",
       ".     0.173335  0.057538  0.081003  0.093320  0.052324  0.089095  0.043963   \n",
       "ADV   0.069891  0.006956  0.030474  0.137131  0.080490  0.343491  0.129182   \n",
       "\n",
       "           ADP      PRON      NOUN         X       PRT  \n",
       "DET   0.009540  0.003744  0.638087  0.045405  0.000242  \n",
       "CONJ  0.052534  0.058113  0.349140  0.008833  0.004649  \n",
       "NUM   0.036033  0.001489  0.350208  0.210542  0.026504  \n",
       ".     0.091342  0.066349  0.222242  0.026971  0.002427  \n",
       "ADV   0.118582  0.014906  0.031467  0.023186  0.014243  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Pre-Processing on validation data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation_tagged_words : [('The', 'DET'), ('company', 'NOUN'), ('said', 'VERB'), ('0', 'X'), ('it', 'PRON')]\n",
      "validation_vocab : ['The', 'company', 'said', '0', 'it']\n"
     ]
    }
   ],
   "source": [
    "validation_tagged_words = [tup for sent in validation for tup in sent]  # list of word and tag\n",
    "print('validation_tagged_words :', validation_tagged_words[:5])\n",
    "validation_vocab = [tup[0] for sent in validation for tup in sent]  # only WORDS\n",
    "print('validation_vocab :',validation_vocab[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running Vanilla Viterbi on Validation Vocablary Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "tagged_seq_vanilla = Viterbi(validation_vocab)  # Viterbi on sample Test Data\n",
    "end = time.time()\n",
    "difference = end-start\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating tagging accuracy for Vanilla Viterbi Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in Minutes:  32.95615941286087\n",
      "Total Correct Tags : 4663\n",
      "Vanilla Viterbi Algorithm Accuracy:  90.91440826671867\n"
     ]
    }
   ],
   "source": [
    "correct_tags_vanilla = [i for i, j in zip(tagged_seq_vanilla, validation_tagged_words) if i == j]\n",
    "accuracy_vanilla = len(correct_tags_vanilla)/len(tagged_seq_vanilla)\n",
    "\n",
    "print(\"Time taken in Minutes: \", difference/60)\n",
    "print('Total Correct Tags :', len(correct_tags_vanilla))\n",
    "print('Vanilla Viterbi Algorithm Accuracy: ',accuracy_vanilla*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solve the problem of unknown words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UNKNOWN WORDS : it is defined as words that are there in TEST data, but not in TRAIN data set.\n",
    "                \n",
    "                subtraction of set is used to get Unknown words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308\n"
     ]
    }
   ],
   "source": [
    "unknown_vocab = list(set(validation_vocab) - set(train_vocab))\n",
    "print(len(unknown_vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    So there are 308, words which are not present in the training vocablary set\n",
    "\n",
    "### Finding Most Frequent Tag for unknown Words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DET': 0, 'CONJ': 0, 'NUM': 29, '.': 0, 'ADV': 2, 'VERB': 62, 'ADJ': 44, 'ADP': 0, 'PRON': 0, 'NOUN': 167, 'X': 14, 'PRT': 0}\n"
     ]
    }
   ],
   "source": [
    "unknown_word_tag_freq = dict([(key, 0) for key in tags])   # Dictionary Creation\n",
    "\n",
    "for ele in validation_tagged_words:\n",
    "    if ele[0] in unknown_vocab:\n",
    "        unknown_word_tag_freq[ele[1]] = unknown_word_tag_freq.get(ele[1],0)+1\n",
    "\n",
    "print(unknown_word_tag_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Note :  From above we see that Most unknown words in the vocablary belongs to the Tag \"NOUN\" \n",
    "            and Assuming a Few Numerical Format Data belong to \"NUM\".\n",
    "\n",
    "### Modified Viterbi Algorithm - 1\n",
    "    Considering the Observation from Above we will try to Improve the Vanilla Viterbi Algorithm using \n",
    "    morphological cues.\n",
    "    1. Identify Numbers using re.search and tag them as NUM\n",
    "    2. Assign all Unknown words the most Frequent Tags ie NOUN in our case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viterbi Heuristic\n",
    "def Viterbi_Rule_Based(words, unknown_word_set, train_bag=train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    for key, word in enumerate(words):\n",
    "        # Using a few Rules to Identify  Numbers \n",
    "        if re.search(r'^-?[0-9]+(.[0-9]+)?$', word):\n",
    "            if word == '0':\n",
    "                state_max = 'X'\n",
    "            else:\n",
    "                state_max = 'NUM'\n",
    "        elif re.search(r'\\*[A-Za-z]*\\*-[0-9]*', word):\n",
    "            state_max = 'X'\n",
    "        elif re.search(r'-[A-Za-z]*-', word):\n",
    "            state_max = '.'\n",
    "        elif word in unknown_word_set:   # tagging unknown words to the Most occured Tag \n",
    "            state_max = 'NOUN'\n",
    "            \n",
    "        # initialise list of probability column for a given observation\n",
    "        else:\n",
    "            p = []\n",
    "            for tag in T:\n",
    "                if key == 0:\n",
    "                    transition_p = tags_df.loc['.', tag]\n",
    "                else:\n",
    "                    transition_p = tags_df.loc[state[-1], tag]\n",
    "\n",
    "                # compute emission and state probabilities\n",
    "                emission_p = word_given_tag(words[key], tag)[0] / word_given_tag(words[key], tag)[1]\n",
    "                state_probability = emission_p * transition_p\n",
    "                p.append(state_probability)\n",
    "\n",
    "            pmax = max(p)\n",
    "            # getting state for which probability is maximum\n",
    "            state_max = T[p.index(pmax)]\n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "tagged_seq_rule = Viterbi_Rule_Based(validation_vocab, unknown_vocab)  # Viterbi on sample Test Data\n",
    "end = time.time()\n",
    "difference = end-start\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating tagging accuracy for Viterbi Algorithm - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in Minutes:  8.038105670611063\n",
      "Total Correct Tags : 4872\n",
      "Rule based Viterbi Algorithm Accuracy:  94.98927666211738\n"
     ]
    }
   ],
   "source": [
    "correct_tags_rule = [i for i, j in zip(tagged_seq_rule, validation_tagged_words) if i == j]\n",
    "accuracy_rule_based = len(correct_tags_rule)/len(tagged_seq_rule)\n",
    "\n",
    "print(\"Time taken in Minutes: \", difference/60)\n",
    "print('Total Correct Tags :', len(correct_tags_rule))\n",
    "print('Rule based Viterbi Algorithm Accuracy: ',accuracy_rule_based*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modified Viterbi Algorithm - 2\n",
    "    \n",
    "    In this Modified version we try to incorporate the probabilistic approch to unknown vacablary set\n",
    "    1. We use Rule based Approch to Tag NUM and X\n",
    "    2. We use a probabilistic Rule that: \n",
    "        for words not in the Training Corpus, their State Probability = Transition Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Viterbi algiorithm with Rule based +  Probabilistic approch\n",
    "def Viterbi_rule_prob(words, unknown_list, train_bag=train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "\n",
    "    for key, word in enumerate(words):\n",
    "        #print(key, word)\n",
    "        if re.search(r'^-?[0-9]+(.[0-9]+)?$', word):\n",
    "            if word == '0':\n",
    "                state_max = 'X'\n",
    "            else:\n",
    "                state_max = 'NUM'\n",
    "        elif re.search('ing',word) or re.search('ed', word):\n",
    "            state_max = 'VERB'\n",
    "        elif re.search(r'\\*[A-Za-z]*\\*-[0-9]*', word):\n",
    "            state_max = 'X'\n",
    "        elif re.search(r'-[A-Za-z]*-', word):\n",
    "            state_max = '.'\n",
    "        elif word in unknown_list:\n",
    "            #print(word)\n",
    "            p=[]\n",
    "            for tag in T:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                state_probability = transition_p\n",
    "                p.append(state_probability)\n",
    "            pmax = max(p)\n",
    "            state_max = T[p.index(pmax)]\n",
    "        # initialise list of probability column for a given observation\n",
    "        else:\n",
    "            p = []\n",
    "            for tag in T:\n",
    "                if key == 0:\n",
    "                    transition_p = tags_df.loc['.', tag]\n",
    "                else:\n",
    "                    transition_p = tags_df.loc[state[-1], tag]\n",
    "\n",
    "                # compute emission and state probabilities\n",
    "                emission_p = word_given_tag(words[key], tag)[0] / word_given_tag(words[key], tag)[1]\n",
    "                state_probability = emission_p * transition_p\n",
    "                p.append(state_probability)\n",
    "\n",
    "            pmax = max(p)\n",
    "            # getting state for which probability is maximum\n",
    "            state_max = T[p.index(pmax)]\n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "tagged_seq_prob = Viterbi_rule_prob(validation_vocab, unknown_vocab)  # Viterbi on sample Test Data\n",
    "end = time.time()\n",
    "difference = end-start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating tagging accuracy for Viterbi Algorithm - 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in Minutes:  7.954983973503113\n",
      "Total Correct Tags : 4803\n",
      "Probality Viterbi Algorithm Accuracy:  93.64398518229675\n"
     ]
    }
   ],
   "source": [
    "correct_tags_prob = [i for i, j in zip(tagged_seq_prob, validation_tagged_words) if i == j]\n",
    "accuracy_probabilistic = len(correct_tags_prob)/len(tagged_seq_prob)\n",
    "\n",
    "print(\"Time taken in Minutes: \", difference/60)\n",
    "print('Total Correct Tags :', len(correct_tags_prob))\n",
    "print('Probality Viterbi Algorithm Accuracy: ',accuracy_probabilistic*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the tagging accuracies of the modifications with the vanilla Viterbi algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Vanilla Viterbi\n",
      "\n",
      "Accuracy of Vanilla Viterbi Algorithm :  90.91440826671867\n"
     ]
    }
   ],
   "source": [
    "print('The Vanilla Viterbi\\n')\n",
    "print('Accuracy of Vanilla Viterbi Algorithm : ',accuracy_vanilla*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified Viterbi Algorithm -2 \n",
      " uses a Probabilistic rule for unknown words that State Probality of Unknown words  =  Transition Probablity\n",
      "\n",
      "Accuracy of Probality based Viterbi Algorithm :  93.64398518229675\n"
     ]
    }
   ],
   "source": [
    "print('Modified Viterbi Algorithm -2 \\n uses a Probabilistic rule for unknown words that State Probality of Unknown words  =  Transition Probablity\\n')\n",
    "print('Accuracy of Probality based Viterbi Algorithm : ',accuracy_probabilistic*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified Viterbi Algorithm - 1 \n",
      " uses a Rule based approch for unknown words ie. tagging unknown words with Most occured POS Tag\n",
      "\n",
      "Accuracy of Probality based Viterbi Algorithm :  94.98927666211738\n"
     ]
    }
   ],
   "source": [
    "print('Modified Viterbi Algorithm - 1 \\n uses a Rule based approch for unknown words ie. tagging unknown words with Most occured POS Tag\\n')\n",
    "print('Accuracy of Probality based Viterbi Algorithm : ',accuracy_rule_based*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List down cases which were incorrectly tagged by original POS tagger and got corrected by your modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# incorrect tagging by Vanilla Viterbi\n",
    "incorrect_tags_vanilla = [j for i, j in zip(tagged_seq_vanilla, validation_tagged_words) if i != j]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_by_Algo_rule = []\n",
    "for ele in incorrect_tags_vanilla:\n",
    "    if ele in correct_tags_rule:\n",
    "        corrected_by_Algo_rule.append(ele[0])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Following Tags got corrected in the Rule based modified Viterbi Algorithm\n",
      "\n",
      "['Deere', 'wave', 'Eveready', 'nickname', 'vagabond', 'existence', 'Miklos', 'Nemeth', '2.6', 'indictment', 'Vice', 'Sherwin', 'Carbide', 'that', '737.5', '3.01', 'ethanol', 'fleet', 'Mount', 'Clemens', 'NYSE', 'Symbol', 'CSV', 'Ketchum', 'Pittsburgh', 'Braun', 'investor-relations', 'marketing-communications', 'escort', 'busloads', 'wives', 'Speedway', 'traffic', 'flood', 'that', '*T*-211', 'rounds', 'verge', 'memo', '89,500', 'that', 'fashion', 'sky', 'railcar', 'platforms', 'Trailer', 'Train', 'up', 'resumption', 'shuttle', 'launch-vehicle', 'engines', '12.82', '133.7', '94', '23.25', 'TREASURY', 'BILLS', 'Results', '7.78', '7.62', 'crapshoot', 'that', '*T*-126', 'document', 'known', 'Form', '8300', 'self', 'sufficiency', 'Payouts', 'Excision', 'riders', 'that', 'prerogative', 'Demand', '*T*-236', 'inside', 'Spending', '2.6', '99.1', 'observance', 'Saints', \"'\", 'Day', 'Datapoint', 'variation', '240,000', 'Asher', '16.2', 'computer-services', 'ballots', 'early', 'most', 'schemes', 'pharaohs', 'playgrounds', 'passions', 'much', '126.1', 'Gelles', 'Wertheim', 'Schroder', 'octogenarians', '*T*-222', 'belfries', 'Anglia', 'that', '*T*-232', 'planting', 'trees', 'that', 'cane', 'Angelo', 'Gaja', 'Barbaresco', 'Piero', 'Antinori', \"'s\", 'Solaia', 'most', 'that', 'chicago', 'report', 'more', 'Legislation', '909', '*T*-260', 'more', 'Congressman', 'Mario', 'Biaggi', 'sentence', 'public', 'Wallach', 'Attorney', 'Meese', 'Morrell', 'meatpacking', 'Brands', 'qualities', 'petroleum', 'Contra', 'Honduras', 'Sandinista', 'offensive', 'rebel', 'out', 'Nemeth', 'twin', 'dams', 'Customers', 'holding', 'most', '170', 'direct', 'Manfred', 'Gingl', 'Taittinger', \"'s\", 'Comtes', 'de', 'more', 'Andrea', 'tutorials', '46.1', '1.85', '1.85', 'that', 'Texan', 'Lloyd', 'Bentsen', '*T*-185', 'oversight', 'tight', 'that', 'refinery', 'that', 'most', 'Dick', 'Lobo', 'WTVJ', 'two-sevenths', 'three-sevenths', '60.36', 'Showa', 'Shell', '1,570', 'Pittsburgh', 'Advanced', '1,298', 'shift', 'more', 'more', 'shift', 'Beige', 'Book', 'up', 'downgrading', 'shivers', 'witches', 'boogieman', 'Advanced', 'Pittsburgh', 'that', 'that', 'species', 'that', '*T*-252', 'up', 'that', 'Clarence', 'Bar', 'Tire', 'Rubber', 'related', 'Albany', 'Packaging', 'drawbacks', 'off', 'insurgents', '*T*-164', '94.2', '83', 'contributors', \"'s\", '*T*-172', 'protein-1', 'that', 'formation', 'most', 'merits', 'up', 'that', '11.57', 'Spaghetti', 'Warehouse', 'editions', 'Editorials', 'disruption', 'schedule', 'taxpayer', 'Nicholas', 'Brady', 'sum', 'homework', 'Fortune', 'schoolboys', 'liabilities', 'face', 'holding', '107.9', '96.4', 'Bar', 'Delegates']\n"
     ]
    }
   ],
   "source": [
    "print('The Following Tags got corrected in the Rule based modified Viterbi Algorithm\\n')\n",
    "print(corrected_by_Algo_rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_by_Algo_prob = []\n",
    "for ele in incorrect_tags_vanilla:\n",
    "    if ele in correct_tags_prob:\n",
    "        corrected_by_Algo_prob.append(ele[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Following Tags got corrected in the Rule based modified Viterbi Algorithm\n",
      "\n",
      "['Deere', 'traced', 'wave', 'nickname', 'glamorize', 'authorized', 'Miklos', 'Nemeth', '2.6', 'indictment', 'Sherwin', 'manipulate', 'Carbide', 'that', '737.5', '3.01', 'centralized', 'ethanol', 'fleet', 'Clemens', 'NYSE', 'Symbol', 'CSV', 'Ketchum', 'Pittsburgh', 'investor-relations', 'escort', 'busloads', 'raced', 'labeling', 'reopened', 'flood', 'that', '*T*-211', 'knocked', '*-128', '*-128', 'synchronized', 'rounds', 'descending', 'verge', 'disseminate', 'memo', '89,500', 'that', 'Bucking', 'drew', 'sky', 'railcar', 'platforms', 'up', 'resumption', 'shuttle', 'launch-vehicle', 'engines', '12.82', '133.7', '94', 'delisted', '23.25', 'TREASURY', 'BILLS', 'Results', '7.78', '7.62', 'crapshoot', 'that', '*T*-126', 'receives', 'document', 'known', '8300', 'self', 'sufficiency', 'Payouts', 'Excision', 'riders', 'that', 'trespass', 'prerogative', 'Demand', '*T*-236', 'inside', '2.6', '99.1', 'muted', 'observance', 'Saints', \"'\", 'oust', 'variation', '240,000', 'underlying', 'provoked', 'Asher', '16.2', 'computer-services', 'averaged', 'ballots', 'relaunched', 'early', 'most', 'building', 'pharaohs', 'playgrounds', 'passions', 'appease', 'counting', 'much', '126.1', 'endorse', 'Gelles', 'Schroder', 'octogenarians', '*T*-222', 'sounding', 'belfries', 'Anglia', 'that', '*T*-232', 'nullified', 'trees', 'that', '*-129', 'increase', 'Piero', 'Antinori', \"'s\", 'Solaia', 'most', 'that', 'mimics', 'chicago', 'report', 'more', 'Legislation', 'ensnarled', '909', '*T*-260', 'more', 'Starting', 'Mario', 'Biaggi', 'sentence', 'bribing', 'public', 'Wallach', 'Attorney', 'Meese', 'alleged', 'Morrell', 'counteract', 'notched', 'searched', 'qualities', 'petroleum', 'Contra', 'offensive', 'rebel', 'phase', 'out', 'Nemeth', 'twin', 'dams', 'Customers', 'holding', 'most', '170', 'direct', 'assisted', \"'s\", 'de', 'encroaching', 'more', 'tutorials', '46.1', '1.85', '1.85', 'swelling', 'that', 'Texan', 'Lloyd', 'Bentsen', 'highlight', '*T*-185', 'oversight', 'tight', 'that', 'wield', 'refinery', 'tightening', 'that', 'most', '*-115', 'Dick', 'Lobo', 'three-sevenths', '60.36', 'Showa', 'Shell', '1,570', 'Pittsburgh', '1,298', 'shift', 'more', 'more', 'shift', 'up', 'boogieman', 'Pittsburgh', 'that', 'that', 'species', 'predicated', 'that', '*T*-252', 'complaining', 'up', 'that', 'Bar', 'Tire', 'Rubber', 'drawbacks', 'brushed', 'off', 'renewing', 'insurgents', '*T*-164', 'happening', 'advanced', '94.2', '83', 'contributors', \"'s\", '*T*-172', 'halve', 'protein-1', 'that', 'most', 'abolishing', 'championing', 'up', 'that', '11.57', 'Spaghetti', 'Warehouse', 'Editorials', 'overused', 'disruption', 'taxpayer', 'Nicholas', 'Brady', 'sum', 'correcting', 'Fortune', 'drooled', 'preferred', 'channel', 'face', 'holding', '107.9', '96.4', 'Bar', 'condemning']\n"
     ]
    }
   ],
   "source": [
    "print('The Following Tags got corrected in the Rule based modified Viterbi Algorithm\\n')\n",
    "print(corrected_by_Algo_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our Two Different Approches taken ie:\n",
    "\n",
    "    1. Rule Based : where Numbers appering were tagged as \"NUM\" and \n",
    "                    All words not in the Training corpus was tagged as \"NOUN\",\n",
    "                    as it was the most appearing TAG\n",
    "    \n",
    "    2. Probablistic : Here numbers were tagged as \"NUM\" --Rule and\n",
    "                      For all Words of Test set not in Training Set, \n",
    "                      their State_probability was set as Transision Prob.\n",
    " \n",
    "#### Result :\n",
    "    \n",
    "    * The Vanila Viterbi had an Accuracy of approx 90%\n",
    "    * Probablistic approch improved this to approx 93%\n",
    "    * Finally we observe that our Rule based Modification gave an Accuracy  approx 95%\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
